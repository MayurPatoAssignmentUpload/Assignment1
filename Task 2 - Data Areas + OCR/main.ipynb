{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import easyocr\n",
    "import pandas as pd\n",
    "from sort.sort import Sort\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'model_weights.pt'\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path, force_reload = True)\n",
    "\n",
    "tracker = Sort()\n",
    "\n",
    "reader = easyocr.Reader(['en'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_text(image):\n",
    "    sharpening_filter = np.array([[-1, -1, -1],\n",
    "                        [-1,  9, -1],\n",
    "                        [-1, -1, -1]])\n",
    "    image = cv2.filter2D(image, -1, sharpening_filter)\n",
    "    image = cv2.fastNlMeansDenoisingColored(image, None, h = 10, hColor = 5, templateWindowSize = 16, searchWindowSize = 5) \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    area = image.shape[0]*image.shape[1]\n",
    "    if (area <= 55000): \n",
    "        image = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 6) \n",
    "    else: \n",
    "        image = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 101, 6) \n",
    "    \n",
    "    text = reader.readtext(image)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main (Code executed in Google Colab): Writing the Processed Frames to an Output file\n",
    "cap = cv2.VideoCapture(\"/content/drive/MyDrive/Assignment1/Test Videos/2.mp4\")\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "out = cv2.VideoWriter('./Output_2.mp4', fourcc, fps, (width, height))\n",
    "\n",
    "ids = {}\n",
    "text_ids = {}\n",
    "parameters = {'RR': ('rr', 'res', 're'),\n",
    "              'Sp02': ('spo', 'sp0'),\n",
    "              'ECG': tuple(['ec'])}\n",
    "            #   'CO2' : tuple(['co2', 'c02'])}\n",
    "            #   'HR': tuple(['hr'])}\n",
    "            #   'Pulse' : tuple(['Pul'])}\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    dframe = np.copy(frame)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        detections = model(frame).xyxy[0].cpu().numpy()\n",
    "\n",
    "    bb_list = []\n",
    "    for row in detections:\n",
    "        x1, y1, x2, y2, _, _ = row\n",
    "        bb_list.append([x1, y1, x2, y2])\n",
    "\n",
    "    if bb_list:\n",
    "        track_list = tracker.update(np.asarray(bb_list))\n",
    "        for area in track_list:\n",
    "            mx1, my1, mx2, my2, id = map(int, area)\n",
    "\n",
    "            if id not in ids:\n",
    "                ids[id] = 'NA'\n",
    "\n",
    "            cv2.rectangle(dframe, (mx1, my1), (mx2, my2), (255, 0, 0), 2)\n",
    "            cv2.putText(dframe, str(ids[id]), (mx1, my1), cv2.FONT_HERSHEY_SIMPLEX, (0.5), (0, 255, 0), 2)\n",
    "            try:\n",
    "                cv2.putText(dframe, f\"{text_ids[id]}: {ids[id]}\", (mx2-50, my1), cv2.FONT_HERSHEY_SIMPLEX, (0.5), (0, 255, 0), 2)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            mframe = frame[my1:my2, mx1:mx2]\n",
    "            if mframe.size:\n",
    "              scaling_factor = 2\n",
    "              sframe = cv2.resize(mframe, None, fx = scaling_factor, fy = scaling_factor, interpolation = cv2.INTER_LINEAR)\n",
    "\n",
    "              text = detect_text(sframe)\n",
    "              max_area = 0\n",
    "              for item in text:\n",
    "                  if not item[1].isdigit():\n",
    "                    # if item[1] == '?':\n",
    "                    #   ids[id] = 'NA'\n",
    "                    #   break\n",
    "                    for key, values in parameters.items():\n",
    "                      for val in values:\n",
    "                          if val in item[1].lower() and id not in text_ids:\n",
    "                              text_ids[id] = key\n",
    "                              break\n",
    "                  elif len(item[1]) < 4:\n",
    "                    area = (item[0][1][0] - item[0][0][0])*(item[0][2][1] - item[0][1][1])\n",
    "                    if area > max_area:\n",
    "                      max_area = area\n",
    "                      ids[id] = int(item[1])\n",
    "\n",
    "    dframe = cv2.cvtColor(dframe, cv2.COLOR_RGB2BGR)\n",
    "    out.write(dframe)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main (Code executed in my PC): Real-Time Detection (Some frames are skipped to improve FPS performance)\n",
    "cap = cv2.VideoCapture(\"Test Videos/2.mp4\")\n",
    "\n",
    "fcount = 0\n",
    "count = 0\n",
    "ids = {}\n",
    "text_ids = {}\n",
    "\n",
    "parameters = {'RR': ('rr', 'res', 're'),\n",
    "              'Sp02': ('spo', 'sp0'),\n",
    "              'ECG': tuple(['ec'])}\n",
    "            #   'CO2' : tuple(['co2', 'c02'])}\n",
    "            #   'HR': tuple(['hr'])}\n",
    "            #   'Pulse' : tuple(['Pul'])}\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: \n",
    "        break\n",
    "    fcount += 1\n",
    "    if fcount%9 != 0: \n",
    "        continue\n",
    "\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    dframe = np.copy(frame) \n",
    "\n",
    "    detections = pd.DataFrame(model(frame).xyxy[0])\n",
    "\n",
    "    bb_list = []\n",
    "    for _, row in detections.iterrows():\n",
    "        x1, y1, x2, y2, _, _ = row\n",
    "        bb_list.append([x1, y1, x2, y2])\n",
    "\n",
    "    if bb_list:\n",
    "        track_list = tracker.update(np.asarray(bb_list))\n",
    "        for area in track_list:\n",
    "            mx1, my1, mx2, my2, id = map(int, area)\n",
    "            if id not in ids: \n",
    "                ids[id] = 'NA'\n",
    "            \n",
    "            cv2.rectangle(dframe, (mx1, my1), (mx2, my2), (255, 0, 0), 2)\n",
    "            cv2.putText(dframe, str(ids[id]), (mx1, my1), cv2.FONT_HERSHEY_SIMPLEX, (0.5), (0, 255, 0), 2)\n",
    "            try:\n",
    "                cv2.putText(dframe, f\"{text_ids[id]}: {ids[id]}\", (mx2-50, my1), cv2.FONT_HERSHEY_SIMPLEX, (0.5), (0, 255, 0), 2)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            if count%9 == 0:\n",
    "                mframe  = frame[my1:my2, mx1:mx2]\n",
    "                scaling_factor = 2\n",
    "                sframe = cv2.resize(mframe, None, fx = scaling_factor, fy = scaling_factor, interpolation = cv2.INTER_LINEAR)\n",
    "                \n",
    "                text = detect_text(sframe)\n",
    "                max_area = 0\n",
    "                for item in text:\n",
    "                    if not item[1].isdigit():\n",
    "                        # if item[1] == '?':\n",
    "                        #     ids[id] = 'NA'\n",
    "                        #     break\n",
    "                        for key, values in parameters.items():\n",
    "                            for val in values:\n",
    "                                if val in item[1].lower() and id not in text_ids:\n",
    "                                    text_ids[id] = key\n",
    "                                    break\n",
    "                    elif len(item[1]) < 4:\n",
    "                        area = (item[0][1][0] - item[0][0][0])*(item[0][2][1] - item[0][1][1])\n",
    "                        if area > max_area:\n",
    "                            max_area = area\n",
    "                            ids[id] = int(item[1])\n",
    "                     \n",
    "        count += 1\n",
    "                                \n",
    "    dframe = cv2.cvtColor(dframe, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imshow(\"Frame\", dframe)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == 27: \n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
